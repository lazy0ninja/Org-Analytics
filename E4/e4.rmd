---
title: "R Notebook"
output: md_document
---

```{r}
library(tidyverse)
library(arrow)
library(tidyverse)
library(lubridate)
library(gender)
library(igraph)
library(dplyr)
```


```{r}
applications <- read_parquet("/Users/kaz/DataspellProjects/Org-Analytics/E3/app_data_sample.parquet")
edges <- read_csv("/Users/kaz/DataspellProjects/Org-Analytics/E3/edges_sample.csv")
```

### get the gender var
```{r}
library(gender)
examiner_names <- applications %>%
  distinct(examiner_name_first)

examiner_names_gender <- examiner_names %>%
  do(results = gender(.$examiner_name_first, method = "ssa")) %>%
  unnest(cols = c(results), keep_empty = TRUE) %>%
  select(
    examiner_name_first = name,
    gender,
    proportion_female)

# remove extra colums from the gender table
examiner_names_gender <- examiner_names_gender %>%
  select(examiner_name_first, gender)

# joining gender back to the dataset
applications <- applications %>%
  left_join(examiner_names_gender, by = "examiner_name_first")

# cleaning up
rm(examiner_names)
rm(examiner_names_gender)
gc()
```


### Get the race var
```{r}

library(wru)

examiner_surnames <- applications %>%
  select(surname = examiner_name_last) %>%
  distinct()

examiner_race <- predict_race(voter.file = examiner_surnames, surname.only = T) %>%
  as_tibble()

examiner_race <- examiner_race %>%
  mutate(max_race_p = pmax(pred.asi, pred.bla, pred.his, pred.oth, pred.whi)) %>%
  mutate(race = case_when(
    max_race_p == pred.asi ~ "Asian",
    max_race_p == pred.bla ~ "black",
    max_race_p == pred.his ~ "Hispanic",
    max_race_p == pred.oth ~ "other",
    max_race_p == pred.whi ~ "white",
    TRUE ~ NA_character_
  ))



# removing extra columns
examiner_race <- examiner_race %>%
  select(surname,race)

applications <- applications %>%
  left_join(examiner_race, by = c("examiner_name_last" = "surname"))

rm(examiner_race)
rm(examiner_surnames)
gc()

```



### Get Tenure
```{r}
library(lubridate) # to work with dates

examiner_dates <- applications %>%
  select(examiner_id, filing_date, appl_status_date)

examiner_dates <- examiner_dates %>%
  mutate(start_date = ymd(filing_date), end_date = as_date(dmy_hms(appl_status_date)))

examiner_dates <- examiner_dates %>%
  group_by(examiner_id) %>%
  summarise(
    earliest_date = min(start_date, na.rm = TRUE),
    latest_date = max(end_date, na.rm = TRUE),
    tenure_days = interval(earliest_date, latest_date) %/% days(1)
  ) %>%
  filter(year(latest_date)<2018)

applications <- applications %>%
  left_join(examiner_dates, by = "examiner_id")

rm(examiner_dates)
gc()
```

### Create Var for application processing time
```{r}
# diff between filing date and patent_issue_date or abandon_date
applications <- applications %>%
  mutate(
    patent_issue_date = ymd(patent_issue_date),
    abandon_date = ymd(abandon_date),
    app_proc_time = case_when(
      !is.na(patent_issue_date) ~ interval(filing_date, patent_issue_date) %/% days(1),
      !is.na(abandon_date) ~ interval(filing_date, abandon_date) %/% days(1),
      TRUE ~ NA_real_
    )
  )
```

**Check the summary stat of the new var**
```{r}
summary(applications$app_proc_time)
```

> Let's delete the erroneous values. For NA values, we will remove them as well for NOW.
```{r}
applications <- applications %>%
  filter(app_proc_time > 0)

# remove na
applications <- applications %>%
  filter(!is.na(app_proc_time))
```



### Graph Network
```{r}
advice_network <- graph_from_data_frame(d = edges[, c("ego_examiner_id", "alter_examiner_id")], directed = TRUE)

degree_centrality <- degree(advice_network, mode = "all")

# Calculate betweenness centrality for each node (examiner)
betweenness_centrality <- betweenness(advice_network, directed = TRUE)

# Create a dataframe of centrality scores
centrality_scores <- data.frame(
  examiner_id = V(advice_network)$name,
  degree = degree_centrality,
  betweenness = betweenness_centrality
)
```
```{r}
applications$examiner_id <- as.character(applications$examiner_id)
centrality_scores$examiner_id <- as.character(centrality_scores$examiner_id)


# erge the centrality scores with the applications data
applications <- applications %>%
  left_join(centrality_scores, by = "examiner_id")
```



### Linear Regression


- Need to chekc the datatypes of cols before running the regression
```{r}
str(applications)
```




# creating more year variables to control for time and possibly age and other time variant factors. Start year may act as a proxy for age

> also create a workgroup variable
```{r}
# create new variables - start year and filling year
applications <- applications %>%
  mutate(
    start_year = year(earliest_date),
    filing_year = year(filing_date)
  )


# create a workgroup variable (first 3 digits of art unit)

applications <- applications %>%
  mutate(
    workgroup = substr(examiner_art_unit, 1, 3)
  )
```

### Convert the start_year to more generic values

```{r}
summary(applications$start_year)
```


```{r}
# Convert start year to more generic values - subtract 2000, which is the min value
applications$start_year <- applications$start_year - 2000
```

```{r}
summary(applications$start_year)
```



```{r}
# count the number of unique examiner art unit
length(unique(applications$examiner_art_unit))

# count the number of unique uspc class
length(unique(applications$uspc_class))

# count the number of unique degree
length(unique(applications$degree))

# count the workgroup
length(unique(applications$workgroup))

```

### Changing the data types of the relevant columns
> I will use workgroup instead of examiner_art_unit
```{r}

# Convert relevant columns to factors
applications$gender <- as.factor(applications$gender)
applications$race <- as.factor(applications$race)
# applications$examiner_art_unit <- as.factor(applications$examiner_art_unit)
applications$workgroup <- as.factor(applications$workgroup)
# applications$start_year <- as.factor(applications$start_year) # decided to treat it as numeric
applications$filling_year <- as.factor(applications$filing_year)
```


```{r}

# Model with interaction term, controlling for other variables
model <- lm(app_proc_time ~ betweenness * gender + degree + tenure_days   + race + start_year + filing_year + workgroup,
            data = applications)

```

```{r}
library(stargazer)
# Using stargazer to generate an HTML table of the model summary
stargazer(model, type = "text", title = "Regression Results")
```

